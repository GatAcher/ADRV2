{"_timestamp": 1597876596.8254201, "PPO_112/train/average_reward": 226.41241455078125, "PPO_112/time/fps": 476.0, "_step": 2010002, "PPO_112/rollout/ep_len_mean": 4999.0, "_runtime": 8832.78687286377, "PPO_112/global_step": 2015232, "PPO_112/rollout/ep_rew_mean": 202.29611206054688, "global_step": 2015232, "PPO_112/train/entropy_loss": -8.380184173583984, "PPO_112/train/explained_variance": -0.301729679107666, "PPO_112/train/policy_gradient_loss": -0.008487343788146973, "PPO_112/train/clip_fraction": 0.35326087474823, "PPO_112/train/std": 0.6908385753631592, "PPO_112/train/learning_rate": 0.0020000000949949026, "PPO_112/train/approx_kl": 0.035430315881967545, "PPO_112/train/value_loss": 0.16507960855960846, "PPO_112/train/clip_range": 0.20000000298023224, "PPO_112/train/loss": 0.07870295643806458, "loss_dif": -1.8124757990241052, "domain_progress": 1, "eval_reward": 15.857130339139585, "best_mean": 2195.478673521249, "best_min": 16.553386902513175}
