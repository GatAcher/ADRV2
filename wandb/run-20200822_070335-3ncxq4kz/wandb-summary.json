{"global_step": 2015232, "_step": 2010002, "_runtime": 43878.01302075386, "PPO_153/train/average_reward": 1966.1651611328125, "_timestamp": 1598083083.5272684, "PPO_153/global_step": 2015232, "PPO_153/rollout/ep_rew_mean": 1829.4921875, "PPO_153/time/fps": 616.0, "PPO_153/rollout/ep_len_mean": 4999.0, "PPO_153/train/clip_range": 0.20000000298023224, "PPO_153/train/std": 0.7274117469787598, "PPO_153/train/explained_variance": -22.90680694580078, "PPO_153/train/clip_fraction": 0.23369565606117249, "PPO_153/train/value_loss": 69.20886993408203, "PPO_153/train/entropy_loss": -8.799019813537598, "PPO_153/train/learning_rate": 0.0020000000949949026, "PPO_153/train/approx_kl": 0.01856554113328457, "PPO_153/train/loss": 29.102678298950195, "PPO_153/train/policy_gradient_loss": -0.013612928800284863, "domain_progress": 1, "loss_dif": -4.539052200317384, "best_mean": 2713.7063345361335, "best_min": -675.7158882956309, "eval_reward": -4.204008054735903}
