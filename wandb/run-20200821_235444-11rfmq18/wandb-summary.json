{"global_step": 2015232, "PPO_146/train/average_reward": 353.9176940917969, "_step": 2010002, "_runtime": 19256.08290863037, "PPO_146/global_step": 2015232, "_timestamp": 1598058461.5971563, "PPO_146/rollout/ep_rew_mean": 351.8946838378906, "PPO_146/rollout/ep_len_mean": 4999.0, "PPO_146/time/fps": 460.0, "PPO_146/train/clip_fraction": 0.43478259444236755, "PPO_146/train/entropy_loss": -8.779799461364746, "PPO_146/train/clip_range": 0.20000000298023224, "PPO_146/train/policy_gradient_loss": -0.01006638165563345, "PPO_146/train/loss": 3.43645977973938, "PPO_146/train/explained_variance": -17.67811393737793, "PPO_146/train/approx_kl": 0.04666915908455849, "PPO_146/train/std": 0.7234803438186646, "PPO_146/train/value_loss": 7.315531253814697, "PPO_146/train/learning_rate": 0.0020000000949949026, "domain_progress": 1, "loss_dif": -0.8877424061298367, "best_mean": 2379.3766917229937, "best_min": 1148.0957490534256, "eval_reward": -30.453534930012104}
