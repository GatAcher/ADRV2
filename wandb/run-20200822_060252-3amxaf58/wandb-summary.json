{"global_step": 2015232, "_step": 2010002, "_runtime": 40605.3692612648, "PPO_152/rollout/ep_len_mean": 4999.0, "_timestamp": 1598079810.883509, "PPO_152/train/average_reward": 1296.7415771484375, "PPO_152/global_step": 2015232, "PPO_152/time/fps": 554.0, "PPO_152/rollout/ep_rew_mean": 690.5443115234375, "PPO_152/train/learning_rate": 0.0020000000949949026, "PPO_152/train/value_loss": 26.349985122680664, "PPO_152/train/approx_kl": 0.019930023699998856, "PPO_152/train/clip_range": 0.20000000298023224, "PPO_152/train/explained_variance": -20.949289321899414, "PPO_152/train/entropy_loss": -7.967451095581055, "PPO_152/train/std": 0.654631495475769, "PPO_152/train/clip_fraction": 0.16847826540470123, "PPO_152/train/policy_gradient_loss": -0.0138182258233428, "PPO_152/train/loss": 10.317179679870605, "domain_progress": 1, "loss_dif": 5.2677155256271355, "best_mean": 1211.811116449992, "best_min": -1.2472168633314373, "eval_reward": 147.58140944000755}
